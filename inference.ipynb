{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels: [-1.] Counts: [3258]\n",
      "Train dataset:\n",
      "Unique labels: [0. 1.] Counts: [1957 8228]\n",
      "Val dataset:\n",
      "Unique labels: [0. 1.] Counts: [ 635 2633]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [00:15<00:00,  6.72it/s]\n",
      "100%|██████████| 102/102 [00:09<00:00, 11.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset:\n",
      "Unique labels: [0. 1.] Counts: [1944 8228]\n",
      "Val dataset:\n",
      "Unique labels: [0. 1.] Counts: [ 648 2633]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [00:15<00:00,  6.66it/s]\n",
      "100%|██████████| 102/102 [00:08<00:00, 11.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset:\n",
      "Unique labels: [0. 1.] Counts: [1877 8048]\n",
      "Val dataset:\n",
      "Unique labels: [0. 1.] Counts: [ 715 2813]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:15<00:00,  7.08it/s]\n",
      "100%|██████████| 102/102 [00:08<00:00, 11.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset:\n",
      "Unique labels: [0. 1.] Counts: [1998 8079]\n",
      "Val dataset:\n",
      "Unique labels: [0. 1.] Counts: [ 594 2782]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106/106 [00:15<00:00,  6.78it/s]\n",
      "100%|██████████| 102/102 [00:08<00:00, 11.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9310344827586207, 0.8131868131868132, 0.8873626373626373, 0.8630952380952381]\n",
      "0.8736697928508274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from src.dataset import get_train_val_loaders, get_test_loader\n",
    "from src.models import MODEL_DICT\n",
    "from src.training import inference_aggregator_loop, get_best_threshold\n",
    "\n",
    "import torch\n",
    "\n",
    "model_name = \"MobileNetV2Tab\"\n",
    "weights_path = [\n",
    "    \"saved_models/run_2024-02-29_18-36-10_MobileNetV2Tab/fold_0_epoch_9_acc_0.9310344827586207.pth\",\n",
    "    \"saved_models/run_2024-02-29_18-36-10_MobileNetV2Tab/fold_1_epoch_17_acc_0.7651098901098901.pth\",\n",
    "    \"saved_models/run_2024-02-29_18-36-10_MobileNetV2Tab/fold_2_epoch_9_acc_0.8543956043956045.pth\",\n",
    "    \"saved_models/run_2024-02-29_18-36-10_MobileNetV2Tab/fold_3_epoch_3_acc_0.8452380952380952.pth\",\n",
    "]\n",
    "\n",
    "loss_function = torch.nn.BCEWithLogitsLoss()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "test_loader = get_test_loader(batch_size=32)\n",
    "\n",
    "test_predictions_list = []\n",
    "ids_list = []\n",
    "balanced_accuracy_list = []\n",
    "\n",
    "for fold in range(4):\n",
    "    model = MODEL_DICT[model_name]().to(device)\n",
    "    model.load_state_dict(torch.load(weights_path[fold]))\n",
    "    model.eval()\n",
    "\n",
    "    train_loader, val_loader = get_train_val_loaders(\n",
    "        batch_size=32, num_workers=4, pin_memory=True, fold_id=fold, fold_numbers=4\n",
    "    )\n",
    "\n",
    "    patient_labels, aggregated_predictions, unique_ids, val_loss = (\n",
    "        inference_aggregator_loop(model, val_loader, device, None)\n",
    "    )\n",
    "\n",
    "    thresholds_sigmoid, thresholds_logits, balanced_accuracy = get_best_threshold(\n",
    "        patient_labels, aggregated_predictions, False\n",
    "    )\n",
    "\n",
    "    _, test_predictions, unique_ids, _ = inference_aggregator_loop(\n",
    "        model, test_loader, device, None\n",
    "    )\n",
    "\n",
    "    test_predictions_list.append((test_predictions > 0.0).astype(int))\n",
    "    ids_list.append(unique_ids)\n",
    "    balanced_accuracy_list.append(balanced_accuracy)\n",
    "\n",
    "print(balanced_accuracy_list)\n",
    "print(sum(balanced_accuracy_list) / len(balanced_accuracy_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9310344827586207, 0.8131868131868132, 0.8873626373626373, 0.8630952380952381]\n"
     ]
    }
   ],
   "source": [
    "print(balanced_accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "only_keep = [0, 1, 2, 3]\n",
    "\n",
    "\n",
    "test_predictions = np.stack(\n",
    "    [pred for i, pred in enumerate(test_predictions_list) if i in only_keep]\n",
    ").mean(axis=0)\n",
    "merged_predictions = (test_predictions > 0.5).astype(int)\n",
    "\n",
    "ids = ids_list[0]\n",
    "ids = [f\"P{i}\" for i in ids]\n",
    "\n",
    "\n",
    "submission = pd.DataFrame({\"Id\": ids, \"Predicted\": merged_predictions})\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
